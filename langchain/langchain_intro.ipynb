{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZi6NDm9npKydMJRyJPAT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudarshan-koirala/youtube-stuffs/blob/main/langchain/langchain_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Intro\n",
        "- https://docs.langchain.com/docs/\n",
        "- [Youtube video covering this notebook](https://youtu.be/jbFHpJhkga8)"
      ],
      "metadata": {
        "id": "28Sbo5BxDXT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- At its core, LangChain is a framework built around LLMs. We can use it for creating chatbots, summarization, Question Answering and many more. The core idea of the library is that we can “chain” together different components to create more advanced use cases around LLMs."
      ],
      "metadata": {
        "id": "iyOYGTrgDg_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick glimpse of LangChain"
      ],
      "metadata": {
        "id": "9IJvl-EEESCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2eVAGw6DTyg"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup\n",
        "- Installing langchain itself, is not enough. Using LangChain will usually require integrations with one or more model providers, data stores, apis, etc.\n",
        "- Let's use OpenAI for this demo"
      ],
      "metadata": {
        "id": "i5sJBalaEiZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "PN7etnX1EfKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set environment variables\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "eZ0GlWotE_S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Large Language Models (LLMs)\n",
        "- Now that we have installed LangChain and set up our environment, we can start building our language model application.\n",
        "- The most basic building block of LangChain is calling an LLM on some input. Let’s walk through a simple example of how to do this. For this purpose, let’s pretend we are building a service that generates a company name based on what the company makes.\n",
        "- In order to do this, we first need to import the LLM wrapper."
      ],
      "metadata": {
        "id": "tRMDrOjtFWGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### For this demo, lets just get predictions\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "ye0QxnfyFUUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the wrapper \n",
        "llm = OpenAI()"
      ],
      "metadata": {
        "id": "GO_IcNIiFtKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we can call it on some input\n",
        "text = \"What would be a good company name for a company that makes colorful shirts?\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZst3FyPGQhF",
        "outputId": "22cff8fd-09fd-4be8-ca3c-c17194e6ee8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "BrightFashionShirts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTT7KZ8FGkLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}